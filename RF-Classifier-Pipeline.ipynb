{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic random-forest classifier - Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions for Aldous:\n",
    "\n",
    "1. Why do your own train/test split instead of sklearn's test_train_split\n",
    "2. Understand the use of 'class' object\n",
    "3. How to interpret 'contributions'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.1.1.19.tar.gz (249kB)\n",
      "\u001b[K    100% |████████████████████████████████| 256kB 4.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /anaconda/lib/python3.6/site-packages (from lime)\n",
      "Requirement already satisfied: scipy in /anaconda/lib/python3.6/site-packages (from lime)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /anaconda/lib/python3.6/site-packages (from lime)\n",
      "Building wheels for collected packages: lime\n",
      "  Running setup.py bdist_wheel for lime ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/joaeechew/Library/Caches/pip/wheels/ba/f0/48/ed6de3efda30be193f2546a3193a0017878b590577f945fc94\n",
      "Successfully built lime\n",
      "Installing collected packages: lime\n",
      "Successfully installed lime-0.1.1.19\n"
     ]
    }
   ],
   "source": [
    "#install as trusted host\n",
    "#!pip install --index-url=http://pypi.python.org/simple/ --trusted-host pypi.python.org lime\n",
    "#!pip install --index-url=http://pypi.python.org/simple/ --trusted-host pypi.python.org treeinterpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import datetime\n",
    "\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# include plots inline in the notebook (ipython specific)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'titanic-train.csv' #Enter data path file here\n",
    "keep = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] #Keep needed features only\n",
    "\n",
    "one_hot_encoding = True #one-hot encoding for categorical values\n",
    "dropna = True #Do you want to drop missing values?\n",
    "impute = False #Do you want to impute missing values?\n",
    "missing_values = 'NaN' #Make sure missing data has been replaced with NaN first\n",
    "impute_strategy = 'most_frequent' # 'most_frequent', 'mean', 'median'\n",
    "scale_features = True #Do you want to scale numerical figures?\n",
    "\n",
    "target = 'Survived' #Target variable\n",
    "\n",
    "seed = 42 #For random state\n",
    "test_size = 0.4 #For train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 891 rows, 12 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read datasets from excel files\n",
    "df = pd.read_csv(path)\n",
    "print(\"Dataset has {} rows, {} columns\".format(*df.shape))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 714 rows, 9 columns\n"
     ]
    }
   ],
   "source": [
    "#### Standardisable pre-processing\n",
    "\n",
    "#Keep needed features only\n",
    "df = df[keep]\n",
    "\n",
    "#Dummy encoding\n",
    "if one_hot_encoding:\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "#Drop missing values\n",
    "if dropna:\n",
    "    df = df.dropna(how='any') #'any', 'all'\n",
    "    \n",
    "if impute:\n",
    "    imp = Imputer(missing_values=missing_values, strategy=impute_strategy, axis=0)\n",
    "    imp.fit_transform(df)\n",
    "    \n",
    "#Scaling of numerical data\n",
    "if scale_features:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit_transform(df)\n",
    "    \n",
    "print(\"Dataset has {} rows, {} columns\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Strings needs to be converted to integers:\n",
    "# 1. Name - This can be removed\n",
    "# 2. Sex - Converted into 1/0\n",
    "# 3. Ticket - Probably insignificant, remove for now.\n",
    "# 4. Cabin - Might represent where they are in the ship, remove for now.\n",
    "# 5. Embarked - 'Matrix conversion' as no levels inherent in number\n",
    "\n",
    "#Remove floats - value too large for random forest\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "df['Fare'] = df['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create response and target variable\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "Here we train and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#Tuning the model\n",
    "param_grid = { \"n_estimators\"      : [100, 150],\n",
    "           \"criterion\"         : [\"gini\"],\n",
    "           \"max_features\"      : ['auto'], #auto, sqrt, log2, int/n_feature\n",
    "           \"max_depth\"         : [5, 20],\n",
    "           \"min_samples_split\" : [2, 4] ,\n",
    "           \"bootstrap\": [True]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "rf_cv = GridSearchCV(rf, param_grid, cv=5)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "rf_best = rf_cv.best_estimator_\n",
    "\n",
    "# Print the tuned parameters\n",
    "print(\"Tuned Parameters: {}\".format(rf_cv.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7762237762237763\n",
      "Best score is 0.8481308411214953\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.91      0.82       165\n",
      "          1       0.83      0.60      0.69       121\n",
      "\n",
      "avg / total       0.78      0.78      0.77       286\n",
      "\n",
      "Tuned Model Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "y_pred = rf_cv.predict(X_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(rf_cv.score(X_test, y_test)))\n",
    "print(\"Best score is {}\".format(rf_cv.best_score_))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: {}\".format(rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "What are the most important drivers of store sales according to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Display feature importance\n",
    "def feature_importance(model, trainData, display_n_rows):\n",
    "    \"\"\"Display feature importance & weighting for tree based model\"\"\"\n",
    "    fi = model.feature_importances_*100\n",
    "    feat_imp = pd.DataFrame(list(zip(fi,trainData.columns.values)))\n",
    "    feat_imp = feat_imp.sort_values(by=0, axis=0, ascending=False)\n",
    "    feat_imp.columns = ['importance %', 'feature']\n",
    "    print(feat_imp[:display_n_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   importance %     feature\n",
      "5     41.920456    Sex_male\n",
      "1     16.694158         Age\n",
      "4     16.309330        Fare\n",
      "0     14.161379      Pclass\n",
      "3      4.039234       Parch\n",
      "2      3.621181       SibSp\n",
      "7      2.631645  Embarked_S\n",
      "6      0.622617  Embarked_Q\n"
     ]
    }
   ],
   "source": [
    "#Display features & weighting\n",
    "feature_importance(rf_best, X_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree interpreter\n",
    "Decomposing random forest predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>ti_bias</th>\n",
       "      <th>ti_prediction</th>\n",
       "      <th>rf_survived_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021701</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.030871</td>\n",
       "      <td>0.160321</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>0.603341</td>\n",
       "      <td>0.865129</td>\n",
       "      <td>0.865129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.029073</td>\n",
       "      <td>-0.339382</td>\n",
       "      <td>-0.035626</td>\n",
       "      <td>-0.047075</td>\n",
       "      <td>-0.047013</td>\n",
       "      <td>0.149743</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.603341</td>\n",
       "      <td>0.265344</td>\n",
       "      <td>0.265344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.078849</td>\n",
       "      <td>-0.006369</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>-0.005866</td>\n",
       "      <td>-0.303161</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.015112</td>\n",
       "      <td>0.603341</td>\n",
       "      <td>0.234655</td>\n",
       "      <td>0.234655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.092888</td>\n",
       "      <td>-0.019648</td>\n",
       "      <td>-0.003330</td>\n",
       "      <td>-0.002585</td>\n",
       "      <td>-0.098342</td>\n",
       "      <td>-0.280361</td>\n",
       "      <td>-0.002093</td>\n",
       "      <td>-0.038413</td>\n",
       "      <td>0.603341</td>\n",
       "      <td>0.065680</td>\n",
       "      <td>0.065680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053182</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>-0.001204</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.070065</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.603341</td>\n",
       "      <td>0.901362</td>\n",
       "      <td>0.901362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass       Age     SibSp     Parch      Fare  Sex_male  Embarked_Q  \\\n",
       "0  0.021701  0.022490  0.002395  0.010680  0.030871  0.160321    0.000219   \n",
       "1 -0.029073 -0.339382 -0.035626 -0.047075 -0.047013  0.149743   -0.000814   \n",
       "2 -0.078849 -0.006369  0.007616  0.002298 -0.005866 -0.303161    0.000532   \n",
       "3 -0.092888 -0.019648 -0.003330 -0.002585 -0.098342 -0.280361   -0.002093   \n",
       "4  0.053182  0.033623 -0.001204  0.007158  0.070065  0.119525    0.001923   \n",
       "\n",
       "   Embarked_S   ti_bias  ti_prediction  rf_survived_proba  \n",
       "0    0.013110  0.603341       0.865129           0.865129  \n",
       "1    0.011243  0.603341       0.265344           0.265344  \n",
       "2    0.015112  0.603341       0.234655           0.234655  \n",
       "3   -0.038413  0.603341       0.065680           0.065680  \n",
       "4    0.013750  0.603341       0.901362           0.901362  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print for all instances \n",
    "\n",
    "#Run tree interpreter\n",
    "prediction, bias, contributions = ti.predict(rf_best, X_test)\n",
    "\n",
    "#Create df\n",
    "survived_contributions = contributions[:, :, 0]\n",
    "df_contributions = pd.DataFrame(survived_contributions, columns=X.columns)\n",
    "df_contributions['ti_bias'] = bias[:,0]\n",
    "df_contributions['ti_prediction'] = prediction[:,0]\n",
    "df_contributions['rf_survived_proba'] = y_pred_proba[:,0]\n",
    "df_contributions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create function to show instance alognside contributions\n",
    "\n",
    "def instance(i):\n",
    "    \"\"\"Actual test example alongside contributions\"\"\"\n",
    "    i_contribution = df_contributions.iloc[i]\n",
    "    i_data = X_test.iloc[i]\n",
    "    i_actual = y_test.iloc[i]\n",
    "\n",
    "    instance = pd.DataFrame(list(zip(X_test.columns.values, i_data, i_contribution)), \n",
    "                            columns = ['Feature', 'Instance', 'Contribution'])\n",
    "    print(\"Instance {} prediction:\".format(i), rf_best.predict(instances.values.reshape(1,-1)))\n",
    "    print(\"Instance {} actual:\".format(i), i_actual)\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write contributions to df\n",
    "df_contributions.to_csv('contributions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 2 prediction: [0]\n",
      "Instance 2 actual: 1\n",
      "      Feature  Instance  Contribution\n",
      "0      Pclass         2     -0.078849\n",
      "1         Age        29     -0.006369\n",
      "2       SibSp         1      0.007616\n",
      "3       Parch         0      0.002298\n",
      "4        Fare        26     -0.005866\n",
      "5    Sex_male         0     -0.303161\n",
      "6  Embarked_Q         0      0.000532\n",
      "7  Embarked_S         1      0.015112\n"
     ]
    }
   ],
   "source": [
    "#Output for example instance\n",
    "instance(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
